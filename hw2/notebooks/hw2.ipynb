{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data!\n",
      "Training model\n",
      "Epoch #1, train loss: 0.7833615498782336, eval acc: 0.885185182094574\n",
      "Epoch #2, train loss: 0.1889492338817991, eval acc: 0.9388889074325562\n",
      "Epoch #3, train loss: 0.1160682053850445, eval acc: 0.9685184955596924\n",
      "Epoch #4, train loss: 0.08210948878115255, eval acc: 0.9462962746620178\n",
      "Epoch #5, train loss: 0.06276779421852, eval acc: 0.970370352268219\n",
      "Epoch #6, train loss: 0.036464868153370265, eval acc: 0.9518518447875977\n",
      "Epoch #7, train loss: 0.023391291077305025, eval acc: 0.979629635810852\n",
      "Epoch #8, train loss: 0.02137927468390683, eval acc: 0.970370352268219\n",
      "Epoch #9, train loss: 0.01584204103218775, eval acc: 0.979629635810852\n",
      "Epoch #10, train loss: 0.006570313448595629, eval acc: 0.9851852059364319\n",
      "Model is trained!\n",
      "Attacking...\n",
      "Eval acc after attack: 0.924074074074074\n",
      "Successful attacks: 33\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3),\n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_seq(x)\n",
    "        x = self.fc1(torch.flatten(x, 1))\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            if len(x.shape) < 4:\n",
    "                x = torch.unsqueeze(x, 0)\n",
    "            res = torch.argmax(self.forward(x), dim=1)\n",
    "        return res\n",
    "\n",
    "\n",
    "def create_datasets():\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    X = X.reshape((-1, 8, 8, 1)).transpose(0, 3, 2, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    dataset = TensorDataset(torch.Tensor(X_train), torch.tensor(y_train, dtype=torch.long))\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    dataset = TensorDataset(torch.Tensor(X_test), torch.tensor(y_test, dtype=torch.long))\n",
    "    test_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct_preds = 0\n",
    "        for X, y in test_loader:\n",
    "            y_hat = model.predict(X)\n",
    "            correct_preds += torch.count_nonzero(y_hat == y)\n",
    "            total += len(y)\n",
    "\n",
    "    return correct_preds / total\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, n_epoch=20):\n",
    "    optimizer = optim.Adam(params=model.parameters())\n",
    "    for ep in range(n_epoch):\n",
    "        train_loss = 0\n",
    "        batches = 0\n",
    "        # with tqdm(train_loader, unit=\"batch\", desc=f'Epoch #{ep}', position=0) as tepoch:\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            y_hat = model(X)\n",
    "            loss = nn.functional.cross_entropy(y_hat, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            batches += 1\n",
    "\n",
    "        train_loss /= batches\n",
    "        eval_acc = eval(model, test_loader)\n",
    "        print(f'Epoch #{ep + 1}, train loss: {train_loss}, eval acc: {eval_acc}')\n",
    "\n",
    "\n",
    "def run_attack(model, test_loader, eps=0.01):\n",
    "    correct = 0\n",
    "    adv_ex = []\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        X.requires_grad = True\n",
    "\n",
    "        y_hat = model(X)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        init_pred = torch.flatten(torch.argmax(y_hat, dim=1)).item()\n",
    "        if init_pred != y.item():\n",
    "            continue\n",
    "\n",
    "        X_grad = X.grad.data\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_new = X + eps * torch.sign(X_grad)\n",
    "            X_new = torch.clip(X_new, 0, 255)\n",
    "\n",
    "            new_pred = model.predict(X_new)\n",
    "\n",
    "        if new_pred.item() == y.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "            adv_ex.append((init_pred, new_pred.item(), X_new.numpy().squeeze(0).transpose(2, 1, 0)))\n",
    "\n",
    "    eval_acc = correct / len(test_loader)\n",
    "    print(f'Eval acc after attack: {eval_acc}')\n",
    "    print(f'Successful attacks: {len(adv_ex)}')\n",
    "\n",
    "    return adv_ex\n",
    "\n",
    "\n",
    "def plot_ex(examples, n_ex=5):\n",
    "    # Plot several examples of adversarial samples at each epsilon\n",
    "    cnt = 0\n",
    "    examples = examples[:n_ex]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    for j in range(len(examples)):\n",
    "        cnt += 1\n",
    "        plt.subplot(1, len(examples), j + 1)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        orig, adv, ex = examples[j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_loader, test_loader = create_datasets()\n",
    "    print('Downloaded data!')\n",
    "\n",
    "    model = Net().to(DEVICE)\n",
    "\n",
    "    print('Training model')\n",
    "    train_model(model, train_loader, test_loader, n_epoch=10)\n",
    "    print('Model is trained!')\n",
    "\n",
    "    print('Attacking...')\n",
    "    adv_ex = run_attack(model, test_loader, eps=0.5)\n",
    "\n",
    "    plot_ex(adv_ex, n_ex=5)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}